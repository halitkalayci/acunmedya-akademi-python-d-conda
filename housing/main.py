# Indexing

# Context => Prompt iÃ§erisinde baÄŸlamÄ± daraltmak iÃ§in kullanÄ±lÄ±r.

# `` => Back Tick

# TÃ¼rkiye Ev Fiyat Tahmini Projesi - Random Forest Modeli
# Bu proje, Random Forest algoritmasÄ± kullanarak TÃ¼rkiye'deki ev fiyatlarÄ±nÄ± tahmin eder.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# TÃ¼rkÃ§e karakter desteÄŸi iÃ§in
plt.rcParams['font.family'] = ['DejaVu Sans']

def load_and_explore_data():
    """Veri setini yÃ¼kle ve keÅŸifsel analiz yap"""
    print("ğŸŒ² Random Forest ile TÃ¼rkiye Ev Fiyat Tahmini")
    print("=" * 50)
    
    # Veri setini yÃ¼kle
    df = pd.read_csv('turkiye_ev_fiyatlari.csv')
    
    print(f"ğŸ“Š Veri Seti Bilgileri:")
    print(f"   â€¢ SatÄ±r sayÄ±sÄ±: {len(df):,}")
    print(f"   â€¢ SÃ¼tun sayÄ±sÄ±: {len(df.columns)}")
    print(f"   â€¢ Eksik deÄŸer: {df.isnull().sum().sum()}")
    
    print(f"\nğŸ’° Fiyat Ä°statistikleri:")
    print(f"   â€¢ Minimum: {df['fiyat_tl'].min():,} TL")
    print(f"   â€¢ Maksimum: {df['fiyat_tl'].max():,} TL")
    print(f"   â€¢ Ortalama: {df['fiyat_tl'].mean():,.0f} TL")
    print(f"   â€¢ Medyan: {df['fiyat_tl'].median():,.0f} TL")
    
    return df

def preprocess_data(df):
    """Veri Ã¶n iÅŸleme"""
    print("\nğŸ”§ Veri Ã–n Ä°ÅŸleme...")
    
    # Kategorik deÄŸiÅŸkenleri encode et
    categorical_columns = ['sehir', 'semt', 'ev_tipi', 'oda_sayisi', 'bina_yasi', 
                          'balkon', 'isitma_tipi', 'otopark', 'site_ici', 'esyali_durum']
    
    df_processed = df.copy()
    label_encoders = {}
    
    for col in categorical_columns:
        le = LabelEncoder()
        df_processed[col] = le.fit_transform(df_processed[col])
        label_encoders[col] = le
    
    # BulunduÄŸu kat sÃ¼tununu iÅŸle (BahÃ§e KatÄ± = 0)
    df_processed['bulundugu_kat'] = df_processed['bulundugu_kat'].replace('BahÃ§e KatÄ±', 0)
    df_processed['bulundugu_kat'] = pd.to_numeric(df_processed['bulundugu_kat'])
    
    print("   âœ… Kategorik deÄŸiÅŸkenler encode edildi")
    
    return df_processed, label_encoders

def train_random_forest(X_train, X_test, y_train, y_test):
    """Random Forest modelini eÄŸit ve optimize et"""
    print("\nğŸŒ² Random Forest Model EÄŸitimi...")
    
    # Temel Random Forest modeli
    print("   ğŸ“ˆ Temel Random Forest modeli eÄŸitiliyor...")
    rf_basic = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    rf_basic.fit(X_train, y_train)
    
    # Temel model tahminleri
    y_pred_basic = rf_basic.predict(X_test)
    
    # Temel model metrikleri
    mae_basic = mean_absolute_error(y_test, y_pred_basic)
    rmse_basic = np.sqrt(mean_squared_error(y_test, y_pred_basic))
    r2_basic = r2_score(y_test, y_pred_basic)
    
    print(f"      â€¢ MAE: {mae_basic:,.0f} TL")
    print(f"      â€¢ RMSE: {rmse_basic:,.0f} TL")
    print(f"      â€¢ RÂ² Score: {r2_basic:.4f}")
    
    # Hiperparametre optimizasyonu
    print("\n   ğŸ” Hiperparametre optimizasyonu yapÄ±lÄ±yor...")
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }
    
    rf_grid = RandomForestRegressor(random_state=42, n_jobs=-1)
    grid_search = GridSearchCV(
        rf_grid, param_grid, cv=3, 
        scoring='neg_mean_absolute_error', 
        n_jobs=-1, verbose=1
    )
    
    grid_search.fit(X_train, y_train)
    
    # En iyi model
    rf_best = grid_search.best_estimator_
    y_pred_best = rf_best.predict(X_test)
    
    # En iyi model metrikleri
    mae_best = mean_absolute_error(y_test, y_pred_best)
    rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))
    r2_best = r2_score(y_test, y_pred_best)
    
    print(f"\n   ğŸ† En Ä°yi Random Forest Modeli:")
    print(f"      â€¢ En iyi parametreler: {grid_search.best_params_}")
    print(f"      â€¢ MAE: {mae_best:,.0f} TL")
    print(f"      â€¢ RMSE: {rmse_best:,.0f} TL")
    print(f"      â€¢ RÂ² Score: {r2_best:.4f}")
    
    return {
        'basic_model': rf_basic,
        'best_model': rf_best,
        'basic_predictions': y_pred_basic,
        'best_predictions': y_pred_best,
        'basic_metrics': {'mae': mae_basic, 'rmse': rmse_basic, 'r2': r2_basic},
        'best_metrics': {'mae': mae_best, 'rmse': rmse_best, 'r2': r2_best},
        'best_params': grid_search.best_params_
    }

def analyze_feature_importance(model, feature_names):
    """Ã–zellik Ã¶nemini analiz et"""
    print("\nğŸ“Š Ã–zellik Ã–nem Analizi...")
    
    # Ã–zellik Ã¶nemlerini al
    importances = model.feature_importances_
    feature_importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    }).sort_values('importance', ascending=False)
    
    print("\n   ğŸ” En Ã–nemli 10 Ã–zellik:")
    for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows(), 1):
        print(f"      {i:2d}. {row['feature']}: {row['importance']:.4f}")
    
    return feature_importance_df

def visualize_results(results, y_test, feature_importance_df):
    """SonuÃ§larÄ± gÃ¶rselleÅŸtir"""
    print("\nğŸ“Š SonuÃ§lar gÃ¶rselleÅŸtiriliyor...")
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Random Forest - TÃ¼rkiye Ev Fiyat Tahmini SonuÃ§larÄ±', fontsize=16, fontweight='bold')
    
    # Model karÅŸÄ±laÅŸtÄ±rmasÄ± (Temel vs Optimize)
    models = ['Temel RF', 'Optimize RF']
    mae_scores = [results['basic_metrics']['mae'], results['best_metrics']['mae']]
    r2_scores = [results['basic_metrics']['r2'], results['best_metrics']['r2']]
    
    # MAE karÅŸÄ±laÅŸtÄ±rmasÄ±
    bars1 = axes[0, 0].bar(models, mae_scores, color=['lightblue', 'darkblue'])
    axes[0, 0].set_title('Mean Absolute Error (MAE)')
    axes[0, 0].set_ylabel('MAE (TL)')
    for i, bar in enumerate(bars1):
        height = bar.get_height()
        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,
                       f'{mae_scores[i]:,.0f}', ha='center', va='bottom')
    
    # RÂ² karÅŸÄ±laÅŸtÄ±rmasÄ±
    bars2 = axes[0, 1].bar(models, r2_scores, color=['lightgreen', 'darkgreen'])
    axes[0, 1].set_title('RÂ² Score')
    axes[0, 1].set_ylabel('RÂ² Score')
    for i, bar in enumerate(bars2):
        height = bar.get_height()
        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,
                       f'{r2_scores[i]:.4f}', ha='center', va='bottom')
    
    # GerÃ§ek vs Tahmin (En iyi model)
    best_pred = results['best_predictions']
    axes[1, 0].scatter(y_test, best_pred, alpha=0.6, color='purple')
    axes[1, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    axes[1, 0].set_xlabel('GerÃ§ek Fiyat (TL)')
    axes[1, 0].set_ylabel('Tahmin Edilen Fiyat (TL)')
    axes[1, 0].set_title('Optimize RF: GerÃ§ek vs Tahmin')
    
    # Ã–zellik Ã¶nemleri (Top 10)
    top_features = feature_importance_df.head(10)
    axes[1, 1].barh(range(len(top_features)), top_features['importance'], color='orange')
    axes[1, 1].set_yticks(range(len(top_features)))
    axes[1, 1].set_yticklabels(top_features['feature'])
    axes[1, 1].set_xlabel('Ã–nem Skoru')
    axes[1, 1].set_title('En Ã–nemli 10 Ã–zellik')
    axes[1, 1].invert_yaxis()
    
    plt.tight_layout()
    plt.savefig('random_forest_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("   âœ… Grafikler 'random_forest_results.png' dosyasÄ±na kaydedildi")

def make_sample_predictions(model, label_encoders, df_original):
    """Ã–rnek tahminler yap"""
    print("\nğŸ”® Ã–rnek Tahminler...")
    
    # Rastgele 5 Ã¶rnek seÃ§
    sample_indices = np.random.choice(df_original.index, 5, replace=False)
    
    for i, idx in enumerate(sample_indices, 1):
        sample = df_original.loc[idx]
        print(f"\n   ğŸ  Ã–rnek {i}:")
        print(f"      â€¢ Åehir: {sample['sehir']}")
        print(f"      â€¢ Ev Tipi: {sample['ev_tipi']}")
        print(f"      â€¢ Oda SayÄ±sÄ±: {sample['oda_sayisi']}")
        print(f"      â€¢ Net mÂ²: {sample['net_metrekare']}")
        print(f"      â€¢ Bina YaÅŸÄ±: {sample['bina_yasi']}")
        print(f"      â€¢ GerÃ§ek Fiyat: {sample['fiyat_tl']:,} TL")
        
        # Tahmin iÃ§in veriyi hazÄ±rla
        sample_encoded = sample.copy()
        categorical_columns = ['sehir', 'semt', 'ev_tipi', 'oda_sayisi', 'bina_yasi', 
                              'balkon', 'isitma_tipi', 'otopark', 'site_ici', 'esyali_durum']
        
        for col in categorical_columns:
            sample_encoded[col] = label_encoders[col].transform([sample[col]])[0]
        
        sample_encoded['bulundugu_kat'] = 0 if sample_encoded['bulundugu_kat'] == 'BahÃ§e KatÄ±' else int(sample_encoded['bulundugu_kat'])
        
        # Tahmin yap
        X_sample = sample_encoded.drop('fiyat_tl').values.reshape(1, -1)
        predicted_price = model.predict(X_sample)[0]
        
        error = abs(sample['fiyat_tl'] - predicted_price)
        error_percent = (error / sample['fiyat_tl']) * 100
        
        print(f"      â€¢ Tahmin Fiyat: {predicted_price:,.0f} TL")
        print(f"      â€¢ Hata: {error:,.0f} TL ({error_percent:.1f}%)")

def main():
    """Ana fonksiyon"""
    try:
        # Veri yÃ¼kleme ve keÅŸif
        df = load_and_explore_data()
        
        # Veri Ã¶n iÅŸleme
        df_processed, label_encoders = preprocess_data(df)
        
        # Ã–zellikler ve hedef deÄŸiÅŸken
        X = df_processed.drop('fiyat_tl', axis=1)
        y = df_processed['fiyat_tl']
        
        # EÄŸitim-test ayrÄ±mÄ±
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        print(f"\nğŸ“š EÄŸitim-Test AyrÄ±mÄ±:")
        print(f"   â€¢ EÄŸitim seti: {len(X_train):,} Ã¶rnek")
        print(f"   â€¢ Test seti: {len(X_test):,} Ã¶rnek")
        
        # Random Forest model eÄŸitimi
        results = train_random_forest(X_train, X_test, y_train, y_test)
        
        # Ã–zellik Ã¶nem analizi
        feature_importance_df = analyze_feature_importance(results['best_model'], X.columns)
        
        # SonuÃ§larÄ± gÃ¶rselleÅŸtir
        visualize_results(results, y_test, feature_importance_df)
        
        # Ã–rnek tahminler
        make_sample_predictions(results['best_model'], label_encoders, df)
        
        print(f"\nğŸ† Final SonuÃ§lar:")
        print(f"   â€¢ En Ä°yi RÂ² Score: {results['best_metrics']['r2']:.4f}")
        print(f"   â€¢ En Ä°yi RMSE: {results['best_metrics']['rmse']:,.0f} TL")
        print(f"   â€¢ En Ä°yi MAE: {results['best_metrics']['mae']:,.0f} TL")
        print(f"   â€¢ En Ä°yi Parametreler: {results['best_params']}")
        
        print(f"\nâœ… Random Forest projesi baÅŸarÄ±yla tamamlandÄ±!")
        print(f"   ğŸ“ Veri seti: turkiye_ev_fiyatlari.csv")
        print(f"   ğŸ“Š SonuÃ§lar: random_forest_results.png")
        
    except FileNotFoundError:
        print("âŒ Hata: 'turkiye_ev_fiyatlari.csv' dosyasÄ± bulunamadÄ±!")
        print("   Ã–nce 'python generate_data.py' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.")
    except Exception as e:
        print(f"âŒ Beklenmeyen hata: {e}")

if __name__ == "__main__":
    main()